{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae9ca86",
   "metadata": {},
   "source": [
    "# [TLDR] trying to understand the text data in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b80ce1",
   "metadata": {},
   "source": [
    "# [LONGER VERSION]\n",
    "- it seems 4 columns contain useful text information re each product\n",
    "  - `title` = French descriptor\n",
    "  - `title_orig` = English translated descriptor\n",
    "  - `tags` = category string, not necessarily uniformly or well partitioned!\n",
    "  - `product_color` = what it says on the tin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3b4e3a",
   "metadata": {},
   "source": [
    "# [RESULT] ACCEPT, BUILD `PRODUCT_DESCRIPTOR` OFF THESE 4 COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba59712",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ipynb_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run class_TokenSearch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe30f19",
   "metadata": {},
   "source": [
    "# IMPLEMENT TEXT SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac49f7f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d=Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.raw.head(1).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a59ffe",
   "metadata": {},
   "source": [
    "### build up regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a20c6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d.df['title'].str.lower().str.contains('summer|hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa0c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.df['title'].str.contains('womens|me|dress|banana',flags=re.IGNORECASE,regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053fae82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.concat(\n",
    "    [\n",
    "        d.df['title'],\n",
    "        d.df['title'].str.contains('sans',flags=re.IGNORECASE,regex=True)+0\n",
    "    ],\n",
    "    axis=1,\n",
    ")[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5a35e",
   "metadata": {},
   "source": [
    "### combine description / tag columns to do single regex on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90177ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d.df[['title','title_orig','tags']].apply(lambda x:x['title']+x['title_orig']+x['tags'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b68678f",
   "metadata": {},
   "source": [
    "# FUNCTIONS TO BUILD UP QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d01d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d=Dataset()\n",
    "ts=TokenSearch(dataset=d)\n",
    "#ts.tokens_found(search_string='harajuku')\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['summer','short'],verbose=1)) # basic logic\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['harajuku'],verbose=1)) # test rare token logic\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['harajuku','sexy'],verbose=1)) # test rare token logic\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['harajuku','goth','sexy'],verbose=1)) # test rare token logic\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['kids'],verbose=1)) # test\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['kids','ball'],verbose=1)) # test\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['balloon'],verbose=1)) # test show_top_n\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['balloon'],verbose=1)) # test results snipping\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['banana'],verbose=1)) # test results chat#\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['sandal'],verbose=1)) # test results chat\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['sandal','red'],verbose=1)) # test results chat\n",
    "d.show_top_n(ts.tokens_found(search_string='sandal red',verbose=1)) # test results chat\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['top','skinny','red'],verbose=1)) # test results chat\n",
    "d.show_top_n(ts.tokens_found(search_tokens=['top','skinny','red'],exact_match=True,verbose=1)) # test results chat\n",
    "d.show_top_n(ts.tokens_found(search_string='top red',verbose=1)) # test results chat\n",
    "d.show_top_n(ts.tokens_found(search_string='top red',exact_match=True,verbose=1)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='exy',verbose=1)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='exy',exact_match=True,verbose=1)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='top red',exact_match=True,verbose=1)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='hot',exact_match=True,verbose=1)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='hot skirt',exact_match=True,verbose=1)) # test non existent search\n",
    "d.show_top_n(ts.tokens_found(search_string='hot skin',exact_match=True,verbose=1)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='hot skinny',exact_match=True,verbose=1)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='hot skinny',exact_match=False,verbose=1)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='skirt slim',exact_match=False,verbose=0)) # test exact search\n",
    "d.show_top_n(ts.tokens_found(search_string='skirt slim',exact_match=False,verbose=0)) # no plotting\n",
    "d.show_top_n(ts.tokens_found(search_string='hot',case_sensitive=True,verbose=1)) # test case sensitive\n",
    "d.show_top_n(ts.tokens_found(search_string='VANGULL',case_sensitive=True,verbose=1)) # test case sensitive\n",
    "d.show_top_n(ts.tokens_found(search_string='VANGULL banana',case_sensitive=True,verbose=1)) # test case sensitive\n",
    "d.show_top_n(ts.tokens_found(search_string='VANGULl',case_sensitive=True,verbose=1)) # test case sensitive\n",
    "d.show_top_n(ts.tokens_found(search_string='VANGUL',case_sensitive=True,verbose=1)) # test case sensitive\n",
    "d.show_top_n(ts.tokens_found(search_string='VANGUL',case_sensitive=True,exact_match=True,verbose=1)) # test case sensitive\n",
    "d.show_top_n(ts.tokens_found(search_string='hot',case_sensitive=True,verbose=1)) # test case sensitive\n",
    "ts.tokens_found(search_string='harajuku',verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
