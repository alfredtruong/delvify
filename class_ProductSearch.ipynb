{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba59712",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ipynb_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfba2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run class_Dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run class_TokenSearch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7428c",
   "metadata": {},
   "source": [
    "# CLASS DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductSearch():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ) -> None :\n",
    "\n",
    "        self.dataset      = Dataset() # initialize Wish dataset\n",
    "        self.token_search = TokenSearch(dataset=self.dataset) # prep token searcher\n",
    "        \n",
    "    def query(\n",
    "        self,\n",
    "        search_string : str,\n",
    "        exact_search  : bool = False,\n",
    "        plot_top_n    : int  = None,\n",
    "        ) -> pd.DataFrame :\n",
    "        ########################################\n",
    "        # step 1 = apply text search\n",
    "        ########################################\n",
    "        token_search_results = self.token_search.tokens_found_count(\n",
    "            search_string = search_string,\n",
    "            exact_search  = exact_search,\n",
    "            verbose       = 1,\n",
    "        )\n",
    "    \n",
    "        ########################################\n",
    "        # step 2 = grab products with most found tokens\n",
    "        ########################################\n",
    "        # TODO # HANDLE CASE WHERE EMPTY DF\n",
    "        max_tokens_matched = token_search_results['tokens_matched'].max()\n",
    "        most_found_token_results = token_search_results[token_search_results['tokens_matched'] == max_tokens_matched]\n",
    "        \n",
    "        ###########################################################\n",
    "        # plot_top_n results\n",
    "        ###########################################################\n",
    "        if (plot_top_n is not None) and len(most_found_token_results)>0:\n",
    "            self.dataset.get_product_pictures(locs=most_found_token_results.index[:plot_top_n])\n",
    "            plt.show()\n",
    "\n",
    "        return most_found_token_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=ProductSearch()\n",
    "ps.query('harajuku beach',plot_top_n=5)\n",
    "#ps.query('dress beach flower dot silt',plot_top_n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
