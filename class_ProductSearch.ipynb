{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f65f687d",
   "metadata": {},
   "source": [
    "# [TLDR] use `token_search`, `nearby_search` and `image_search` together the return products to the user "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8cb62c",
   "metadata": {},
   "source": [
    "# [LONGER VERSION]\n",
    "- approach taken is follows\n",
    "  1. [token_results] look for products by matching the user-provided `search_string` tokens to the `product_descriptor`\n",
    "    - `product_descriptor` is made by concatenating `title`, `title_orig`, `tags` and `product_color`\n",
    "    - [token_results] are ordered by considering their \"highest PROPORTION of 4 and 5 star ratings\", do so avoids the following problems\n",
    "      - results could be dominated by old products with lots of reviews, both good and bad (i.e. highest COUNT of 4 and 5 star ratings would skew to returning veteran products)\n",
    "      - results could be dominated by old products with lots of `units_sold` (i.e. lots sold could simply mean the product has been sold for a long time)\n",
    "    - considering \"highest PROPORTION of 4 and 5 star ratings\" is good as\n",
    "      - it allows new products that trend to get to the top of the list\n",
    "\n",
    "  2a. if [token_results] are more numerous than some \"min results count\" we're done (i.e. 25 [token_results] we found and we need only show 20 results)\n",
    "  \n",
    "  2b. otherwise we grab new products considering [nearby_results]\n",
    "    - [nearby_results] are new products that are similar to [token_results] in numerical space\n",
    "    - they are found by grabbing `kNeighbors` from our [token_results]\n",
    "    - new results don't care about search string tokens\n",
    "    - we can keep adding to [nearby_results] by increasing `n_nearest` considered from [token_result] until the \"min results count\" is breached\n",
    "    - [nearby_results] are ordered by taking each [nearby_results] shortest distance to a [token_results]\n",
    "    \n",
    "  3a. if the `spotlight` parameter is NOT specified in the `query` we simply return \"min results count\" results by stacking ordered [token_results] ordered [nearby_results]\n",
    "  \n",
    "  3b. otherwise [image_search] is used to order [nearby_results] by measure `psnr` from the `spotlight` product\n",
    "    - the `spotlight` product must be specfied by the user\n",
    "    - it only considers the distance of [nearby_results] from the `spotlight` product and NOT [token_results]\n",
    "    - more [nearby_results] are found so as to give more options for the [image_search] to act on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba59712",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ipynb_setup.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfba2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run class_Dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db2fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run class_TokenSearch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1ab55e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run class_NeighbourSearch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb0680f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run class_ImageSearch.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf7428c",
   "metadata": {},
   "source": [
    "# CLASS DEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907a8ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ProductSearch():\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ) -> None :\n",
    "\n",
    "        self.dataset         = Dataset() # initialize Wish dataset\n",
    "        self.token_search    = TokenSearch(dataset=self.dataset) # prep token searcher\n",
    "        self.neighbor_search = NeighbourSearch(dataset=self.dataset) # prep nearest neighbor searcher\n",
    "        self.image_search    = ImageSearch(dataset=self.dataset) # prep image searcher\n",
    "\n",
    "    # this given top rating products precedence over units sold, allows good products to trend rather than old products to stay at the top\n",
    "    def reorder_on_top_ratings(\n",
    "        self,\n",
    "        res : pd.DataFrame,\n",
    "        ) -> pd.DataFrame :\n",
    "        top_rating_pctage = (res['rating_five_count']+res['rating_four_count'])/res['rating_count']\n",
    "        top_rating_pctage = top_rating_pctage.sort_values(ascending=False)\n",
    "        return res.loc[top_rating_pctage.index,:]\n",
    "\n",
    "    def chatbot(\n",
    "        self,\n",
    "        res : pd.DataFrame,\n",
    "        ) -> None:\n",
    "        if len(res)==0:    print(f'[token results]: I got nothing! T⌓T') # unhappy\n",
    "        elif len(res)==1:  print(f'[token results]: only 1 hit ￣ω￣, I hope it\\'s what you wanted!') # unsure\n",
    "        elif len(res)<=5:  print(f'[token results]: {len(res)} results, see anything you like?') # tight search\n",
    "        else: print(f'[token results]: {len(res)} results found') # normal\n",
    "\n",
    "    # find products that match purely on tokens + sort them on \"top ratings\" (allow new top rated products to trend rather than old products with any units_sold to dominate results)\n",
    "    def query(\n",
    "        self,\n",
    "        search_string         : str,\n",
    "        exact_match           : bool  = False,\n",
    "        case_sensitive        : bool  = False,\n",
    "        required_results      : int   = 20,  # token matching results at the top (with )\n",
    "        spotlight             : int   = None, # for ImageSearch\n",
    "        spotlight_extra_ratio : float = 2,    # ratio vs `required_results` of additional results needed for image search to to help refine / acquire\n",
    "        show_results          : bool  = True,\n",
    "        chatbot               : bool  = True,\n",
    "        verbose               : int   = 0,\n",
    "        ) -> pd.DataFrame :\n",
    "\n",
    "        # validate input\n",
    "        if spotlight is not None:\n",
    "            if spotlight not in self.dataset.df.index:\n",
    "                print(f'spotlighted product {spotlight} not recognized, please try again with a known product ID')\n",
    "                spotlight = None\n",
    "            \n",
    "        # protect input\n",
    "        if required_results > len(self.dataset.df): required_results = len(self.dataset.df)\n",
    "\n",
    "        ###########################################################\n",
    "        # step 1 = get token_matching_results\n",
    "        ###########################################################\n",
    "        token_results = self.token_search.tokens_found(\n",
    "            search_tokens  = None,\n",
    "            search_string  = search_string,\n",
    "            exact_match    = exact_match,\n",
    "            case_sensitive = case_sensitive,\n",
    "            verbose        = verbose,\n",
    "        )\n",
    "        if verbose>2: print('token_results');display(token_results)\n",
    "        \n",
    "        ###########################################################\n",
    "        # chatbot\n",
    "        ###########################################################\n",
    "        if chatbot: self.chatbot(token_results)\n",
    "\n",
    "        if len(token_results) == 0: \n",
    "            print('search too specific')\n",
    "            return\n",
    "\n",
    "        ###########################################################\n",
    "        # step 2 = ensure we have enough results\n",
    "        ###########################################################\n",
    "        if len(token_results) >= required_results:\n",
    "            # if enough results already we're good\n",
    "            final_results = token_results[:required_results] # snip token_results\n",
    "\n",
    "            # sort results on \"high ratings\", this allows new top rated products (that haven't sold a lot to trend rather than just having old products with many units_sold dominating results)\n",
    "            final_results = self.reorder_on_top_ratings(final_results)\n",
    "        else:\n",
    "            # if should use ImageSearch to order or not?\n",
    "            if spotlight is None:\n",
    "                # no spotlight product given, just pad up to required_results\n",
    "                \n",
    "                # use nearest neighbour in numerical space to get more results regardless of token matching\n",
    "                padded_results_distances = self.neighbor_search.nearby_results(\n",
    "                    locs        = token_results.index, # token_results are source to search from\n",
    "                    min_results = int(required_results),\n",
    "                )\n",
    "                if verbose>2: print('padded_results_distances');display(padded_results_distances)\n",
    "            \n",
    "                # sort non-token_results as follows\n",
    "                # (a) for token_results, use \"high ratings\"\n",
    "                token_results_order  = list(self.reorder_on_top_ratings(token_results).index)\n",
    "                \n",
    "                # (b) for nearby results, use distance from token_results\n",
    "                nearby_results_order = padded_results_distances[:required_results] # trim to required number\n",
    "                nearby_results_order = list(nearby_results_order[nearby_results_order!=0].index) # of the non 0 distance results (i.e. nearby results), take whatever is required to get up to `required_results`\n",
    "                print(f'[nearby results]: {len(nearby_results_order)} results added')\n",
    "                \n",
    "                # (c) token_results first then nearby_results after\n",
    "                padded_results_final_order = token_results_order + nearby_results_order\n",
    "                    \n",
    "                # extract df with final_order\n",
    "                final_results = self.dataset.df.loc[padded_results_final_order] # get in order of \n",
    "            else:\n",
    "                # spotlight product given, get more results than asked for to Image search over\n",
    "                \n",
    "                # get more than required_results to image search over\n",
    "                if spotlight_extra_ratio < 1: spotlight_extra_ratio = 1\n",
    "\n",
    "                # use nearest neighbour in numerical space to get more results regardless of token matching\n",
    "                padded_results_distances = self.neighbor_search.nearby_results(\n",
    "                    locs        = token_results.index, # token_results are source to search from\n",
    "                    min_results = int(required_results * spotlight_extra_ratio),\n",
    "                )\n",
    "                if verbose>2: print('padded_results_distances');display(padded_results_distances)\n",
    "\n",
    "                # sort non-token_results as follows\n",
    "                # (a) for token_results, use \"high ratings\"\n",
    "                token_results_order  = list(self.reorder_on_top_ratings(token_results).index)\n",
    "\n",
    "                # (b) for nearby results, use distance from spotlight\n",
    "                nearby_results_order = list(padded_results_distances[padded_results_distances!=0].index) # of the non 0 distance results (i.e. nearby results), take whatever is required to get up to `required_results`\n",
    "                print(f'[nearby results]: {len(nearby_results_order)} results added')\n",
    "                #display(nearby_results_order)\n",
    "                psnr = self.image_search.img_similarity_tgt_locs(\n",
    "                    plot_src  = False,\n",
    "                    grayscale = True,\n",
    "                    blur      = True,\n",
    "                    src_loc   = spotlight,\n",
    "                    tgt_locs  = nearby_results_order,\n",
    "                )\n",
    "                psnr = psnr[np.isfinite(psnr).values] # remove comparisons with self, i.e. inf's\n",
    "                psnr = psnr['psnr'].sort_values(ascending=False)\n",
    "                \n",
    "                # (c) token_results first then nearby_results after\n",
    "                padded_results_final_order = token_results_order + nearby_results_order\n",
    "                padded_results_final_order = padded_results_final_order[:required_results] # trim to required number\n",
    "                print(f'[image ordering]: {len(padded_results_final_order)} final results')\n",
    "                \n",
    "                # extract df with final_order\n",
    "                final_results = self.dataset.df.loc[padded_results_final_order] # get in order of \n",
    "        \n",
    "        ###########################################################\n",
    "        # step 3 = show_top_n results\n",
    "        ###########################################################\n",
    "        if show_results: self.dataset.show_top_n(final_results,n=required_results)\n",
    "\n",
    "        return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7381e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ps=ProductSearch()\n",
    "#ps.query('harajuku',required_results=20)\n",
    "#res=ps.query('harajuku',spotlight_extra_ratio=0.1)\n",
    "#ps.query('harajuku beach')\n",
    "#ps.query('harajuku pop')\n",
    "#ps.query('dress')\n",
    "#ps.query('dress beach')\n",
    "#ps.query('dress beach flower')\n",
    "#ps.query('dress beach flower sleeve')\n",
    "#ps.query('dress beach flower blue')\n",
    "#ps.query('dress beach flower blue',spotlight=1225) # good spotlight\n",
    "#ps.query('dress beach flower blue',spotlight='asdf') # bad spotlight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
